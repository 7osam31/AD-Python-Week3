"""
Day 13 Activity: Large Dataset Cleaning
Tasks:
1) Read CSV in chunks
2) Clean each chunk (e.g., numeric conversion)
3) Append cleaned chunks to output CSV
4) Track basic performance metrics
"""

import pandas as pd
import time
df=pd.read_csv("C:\\Users\\acer57\\OneDrive\\Desktop\\my web\\python\\day13_large_users.csv",chunksize=100)

# TODO: Implement clean_chunk(df)
def clean_chunk(df: pd.DataFrame) :
    for col in df.columns:
        if col in ["age", "income"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df

# TODO: Implement process_large_file(path_in, path_out, chunksize)



start = time.perf_counter()
for chunk in df:
    cleaned = clean_chunk(chunk)
elapsed = time.perf_counter() - start
print(f"Chunk cleaned in {elapsed:.3f} seconds")
